# NVIDIA Parakeet TDT 0.6B v3 Fine-tuning Configuration
# OPTIMIZED FOR FULL DATASET TRAINING (5.2M samples)
# Memory-optimized for A100-80GB with 8-bit optimizer and gradient checkpointing

model:
  # Pre-trained model from HuggingFace/NVIDIA
  name: "nvidia/parakeet-tdt-0.6b-v3"
  
  # Memory optimization: Enable gradient checkpointing (30-50% memory savings)
  gradient_checkpointing: true

data:
  # NeMo manifest files (JSONL format)
  train_manifest: "./data/train_manifest.json"
  val_manifest: "./data/val_manifest.json"
  
  # Dataset size - FULL DATASET
  max_samples: -1  # Use all ~5.2M samples
  
  # Audio processing
  sampling_rate: 16000
  max_audio_length: 30.0  # seconds
  min_audio_length: 0.1   # seconds

training:
  # Output directory
  output_dir: "./outputs/parakeet-tdt-malay-asr-full"
  run_name: "parakeet-tdt-malay-full-dataset"
  
  # Training epochs and steps
  num_train_epochs: 1.0
  max_steps: -1
  
  # Batch size and accumulation (OPTIMIZED FOR MEMORY)
  # With 8-bit optimizer + gradient checkpointing:
  # Effective batch size = 20 * 6 = 120
  per_device_train_batch_size: 20   # Increased with memory optimizations
  per_device_eval_batch_size: 10    # Increased with memory optimizations
  gradient_accumulation_steps: 6    # Balanced for ~120 effective batch size
  
  # Optimizer settings - USE 8-BIT OPTIMIZER for 75% memory reduction
  optimizer: "adamw_8bit"  # Requires: pip install bitsandbytes
  # optimizer: "adamw8bit" # Alternative naming (also works)
  learning_rate: 2.0e-4
  weight_decay: 0.0001
  max_grad_norm: 1.0
  
  # Learning rate scheduler
  scheduler: "CosineAnnealing"
  warmup_steps: 500      # Increased for larger dataset
  min_learning_rate: 1.0e-6
  
  # Precision and optimization
  fp16: false
  bf16: true  # A100/H100 optimized
  
  # Logging and evaluation (ADJUSTED FOR FULL DATASET)
  logging_steps: 50      # Log more frequently
  eval_steps: 10000      # Eval every 10k steps (larger dataset = less frequent)
  save_steps: 10000      # Must match eval_steps for load_best_model_at_end
  save_total_limit: 3    # Keep only best 3 checkpoints
  load_best_model_at_end: true
  
  # DataLoader settings
  dataloader_num_workers: 16  # Increased for better I/O throughput
  dataloader_pin_memory: true
  
  # Resume from checkpoint (useful for progressive training)
  resume_from_checkpoint: false
  
  # Hardware
  num_gpus: 1  # Set to 2+ for multi-GPU training

# Weights & Biases (optional)
wandb:
  enabled: false
  project: "parakeet-tdt-malay-asr-full"
  entity: null
  run_name: "parakeet-tdt-full-dataset"

# Notes:
# 1. REQUIRES: pip install bitsandbytes (for 8-bit optimizer)
# 2. Memory usage: ~50-55GB on A100-80GB (vs 80GB+ without optimizations)
# 3. Effective batch size: 20 * 6 = 120 (maintains good training dynamics)
# 4. Gradient checkpointing: Trades ~15% speed for ~30-50% memory
# 5. 8-bit optimizer: Trades ~5% speed for ~75% optimizer memory
# 6. Combined memory savings: ~25-30GB compared to baseline
# 7. Expected training time: ~24 hours on A100-80GB (full 5.2M samples, 1 epoch)
# 8. For faster training: Use 2+ GPUs and increase num_gpus
# 9. If still OOM: Reduce batch to 16/8, increase grad_accum to 8
# 10. Progressive training: Start with 100k samples, then 500k, then 1M, then full

# Multi-GPU Example (if you have multiple GPUs):
# training:
#   num_gpus: 2  # Use 2 GPUs
#   per_device_train_batch_size: 32  # Can increase with more memory
#   gradient_accumulation_steps: 2   # Effective batch = 32*2*2 = 128


